---
title             : "Sexism and Division of Labor on Feelings of Teamliness Within Household Dyads"
shorttitle        : "Sexism and Feelings of Teamliness"

author: 
  - name          : "Naomi Liftman"
    affiliation   : "1" 
  - name          : "Cara Krupnikoff-Salkin"
    affiliation   : "1"
    role:
      - Writing - Review & Editing

affiliation:
  - id            : "1"
    institution   : "Smith College"


  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["psy-references.bib", "r-references.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : no
mask              : no
draft             : no

documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
library("papaja")
library("tidyverse")
library("lubridate")
library("psych")
library("mosaic")
library("nlme")
library("kableExtra")
r_refs("r-references.bib")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

```{r include = FALSE, message = FALSE, warning = FALSE}
#loading all the files
library(tidyverse)
library(lubridate)
library(psych)
library(mosaic)
library(nlme)
library(kableExtra)
###############################################################################
#PREMEASURES
# Loading the data 
pre <- read_csv("TeleCom_Dyad_premeasures.csv")

pre <- pre %>% 
  select(ResponseId, dyadID, Q138, cohabitation, wfh, gender, sexualor, race, 
         religion, conservatism, people_4_TEXT, people_5_TEXT, indinc, 
         asi_1:asi_22)

# Making ASI numeric
pre <- pre %>%
  mutate(asi_1 = as.numeric(gsub("[a-zA-Z]", "", asi_1)),
         asi_2 = as.numeric(gsub("[a-zA-Z]", "", asi_2)),
         asi_3 = as.numeric(gsub("[a-zA-Z]", "", asi_3)),
         asi_4 = as.numeric(gsub("[a-zA-Z]", "", asi_4)),
         asi_5 = as.numeric(gsub("[a-zA-Z]", "", asi_5)),
         asi_6 = as.numeric(gsub("[a-zA-Z]", "", asi_6)),
         asi_7 = as.numeric(gsub("[a-zA-Z]", "", asi_7)),
         asi_8 = as.numeric(gsub("[a-zA-Z]", "", asi_8)),
         asi_9 = as.numeric(gsub("[a-zA-Z]", "", asi_9)),
         asi_10 = as.numeric(gsub("[a-zA-Z]", "", asi_10)),
         asi_11 = as.numeric(gsub("[a-zA-Z]", "", asi_11)),
         asi_12 = as.numeric(gsub("[a-zA-Z]", "", asi_12)),
         asi_13 = as.numeric(gsub("[a-zA-Z]", "", asi_13)),
         asi_14 = as.numeric(gsub("[a-zA-Z]", "", asi_15)),
         asi_15 = as.numeric(gsub("[a-zA-Z]", "", asi_15)),
         asi_16 = as.numeric(gsub("[a-zA-Z]", "", asi_16)),
         asi_17 = as.numeric(gsub("[a-zA-Z]", "", asi_17)),
         asi_18 = as.numeric(gsub("[a-zA-Z]", "", asi_18)),
         asi_19 = as.numeric(gsub("[a-zA-Z]", "", asi_19)),
         asi_20 = as.numeric(gsub("[a-zA-Z]", "", asi_20)),
         asi_21 = as.numeric(gsub("[a-zA-Z]", "", asi_21)),
         asi_22 = as.numeric(gsub("[a-zA-Z]", "", asi_22)))

# Reverse-coding relevant questions 
pre <- pre %>% 
  mutate(asi_3.r = (1+6) - asi_3,
         asi_6.r = (1+6) - asi_6,
         asi_7.r = (1+6) - asi_7,
         asi_13.r = (1+6) - asi_13,
         asi_18.r = (1+6) - asi_18,
         asi_21.r = (1+6) - asi_21)

# Benevolent correlation matrix
corr.test(select(pre, asi_1, asi_3.r, asi_6.r, asi_8, asi_9, asi_12, asi_13.r, 
                 asi_17, asi_19, asi_20, asi_22))$r

# Hostile correlation matrix
corr.test(select(pre, asi_2, asi_4, asi_5, asi_7.r, asi_10, asi_11, asi_14, 
                 asi_15, asi_16, asi_21.r))$r
#we did not include question 18

# ASI reliability
# Reliability for the benevolent
alpha(select(pre, asi_1, asi_3.r, asi_6.r, asi_8, asi_9, asi_12, asi_13.r, 
             asi_17, asi_19, asi_20, asi_22))
#raw alpha is 0.8001697

# Reliability for the hostile
alpha(select(pre, asi_2, asi_4, asi_5, asi_7.r, asi_10, asi_11, asi_14, 
             asi_15, asi_16, asi_21.r))
#raw alpha is 0.8743657 without question 18

# Benevolent own variable
pre$bs <- rowMeans(select(pre, asi_1, asi_3.r, asi_6.r, asi_8, asi_9, asi_12, 
                          asi_13.r, asi_17, asi_19, asi_20, asi_22))

# Hostile own variable, without question 18
pre$hs <- rowMeans(select(pre, asi_2, asi_4, asi_5, asi_7.r, asi_10, asi_11, 
                          asi_14, asi_15, asi_16, asi_21.r))
###############################################################################
#DAILY
# Loading the data
daily <- read_csv("TeleCom_Dyad_dailydiary.csv")

daily <- daily %>%
  mutate(RecordedDate = mdy_hm(RecordedDate)) %>%
  arrange(dyadID, partID, day, RecordedDate) %>%
  mutate(ResponseID = seq_along(RecordedDate)) %>%
  group_by(partID, day) %>%
  mutate(RecordedDate_lag = lag(RecordedDate), #so we can test if record for second tuesday are plausibly next week
         dist = difftime(RecordedDate, RecordedDate_lag, units = "days"), #recoding as day between
         first_sec = seq_along(RecordedDate), #first tuesday or second tuesday?
         prob = ifelse(first_sec >= 2 & dist < 4, 1, 0)) %>% #second+ tuesday is problematic if it's NOT plausibly next week
  group_by(dyadID, partID) %>%
  arrange(dyadID, partID, RecordedDate) %>%
  mutate(rec_num = seq_along(RecordedDate),
         weekish = ifelse(rec_num > 7, 2, 1), #coding for days beyond 7, most are "week 2"
         day_of_study = ifelse(weekish == 2 | (weekish==1 & first_sec>1), #for people who missed days in week 1
                        (case_when(day == "Monday" ~ 8,
                        day == "Tuesday" ~ 9,
                        day == "Wednesday" ~ 10,
                        day == "Thursday" ~ 11,
                        day == "Friday" ~ 12,
                        day == "Saturday" ~ 13,
                        day == "Sunday" ~ 14)), 
                      case_when(day == "Monday" ~ 1,
                        day == "Tuesday" ~ 2,
                        day == "Wednesday" ~ 3,
                        day == "Thursday" ~ 4,
                        day == "Friday" ~ 5,
                        day == "Saturday" ~ 6,
                        day == "Sunday" ~ 7)),
         week = ifelse(day_of_study > 7, 2, 1)) %>%
  group_by(partID) %>%
  mutate(problems = sum(prob)) %>%
  arrange(desc(problems), dyadID, partID, RecordedDate) %>%
  select(ResponseID, partID_given:day, day_of_study, RecordedDate_lag, dist, 
         first_sec, prob, rec_num,  
          weekish, week, problems, gender:comments)

#remove anyone with 
#(problems > 1) | (problems == 1 & !is.na(partID_given)) 
daily <- daily %>% 
  filter((problems <= 1) | (problems != 1) & (!is.na(partID_given)))

#other problematic cases or IDs to filter out completely: 
#146, 1266, 1278, 1282, 1302, partID == R_1fiPEJydpvuaEEs, R_1jV9NyWEbelB76s,R_1PTxhk4207mTHAb, R_27kuznipTrWICLB, 2800
daily <- daily %>% 
  filter(ResponseID != 146, ResponseID != 1266, ResponseID != 1278,  
         ResponseID != 1282, ResponseID != 1302, ResponseID != 2800) %>% 
  filter(partID != 'R_1fiPEJydpvuaEEs', partID != 'R_1jV9NyWEbelB76s', 
         partID != 'R_1PTxhk4207mTHAb', partID != 'R_27kuznipTrWICLB')

#other problematic cases to fix due to participant error:
daily <- daily %>% 
  mutate(day = ifelse(ResponseID == 494, "Friday", day),
         day = ifelse(ResponseID == 771, "Wednesday", day),
         day = ifelse(ResponseID == 873, "Monday", day),
         day = ifelse(ResponseID == 887, "Monday", day),
         day = ifelse(ResponseID == 1077, "Wednesday", day),
         day = ifelse(ResponseID == 1111, "Saturday", day),
         day = ifelse(ResponseID == 1202, "Wednesday", day),
         day = ifelse(ResponseID == 1219, "Tuesday", day),
         day = ifelse(ResponseID == 1233, "Tuesday", day),
         day = ifelse(ResponseID == 1247, "Tuesday", day),
         day = ifelse(ResponseID == 1365, "Saturday", day),
         day = ifelse(ResponseID == 1771, "Friday", day),
         day = ifelse(ResponseID == 1785, "Friday", day),
         day = ifelse(ResponseID == 2328, "Wednesday", day),
         day = ifelse(ResponseID == 2345, "Saturday", day),
         day = ifelse(ResponseID == 2393, "Wednesday", day),
         day = ifelse(ResponseID == 2516, "Thursday", day),
         day = ifelse(ResponseID == 2680, "Monday", day),
         day = ifelse(ResponseID == 2694, "Monday", day),
         day = ifelse(ResponseID == 2821, "Saturday", day),
         day = ifelse(ResponseID == 2825, "Sunday", day),
         day = ifelse(ResponseID == 2859, "Wednesday", day),
         day = ifelse(ResponseID == 2881, "Sunday", day),
         day = ifelse(ResponseID == 2940, "Thursday", day),
         day = ifelse(ResponseID == 3005, "Monday", day),
         day = ifelse(ResponseID == 3025, "Thursday", day),
         day = ifelse(ResponseID == 3178, "Monday", day),
         day = ifelse(ResponseID == 3192, "Monday", day),
         day = ifelse(ResponseID == 3243, "Sunday", day),
         day = ifelse(ResponseID == 3385, "Wednesday", day),
         day = ifelse(ResponseID == 3399, "Wednesday", day))

daily <- daily %>% 
  mutate(day_of_study = ifelse(ResponseID == 894, 8, day_of_study))

#run again after clean:
daily <- daily %>%
  arrange(dyadID, partID, day, RecordedDate) %>%
  mutate(ResponseID = seq_along(RecordedDate)) %>%
  group_by(partID, day) %>%
  mutate(RecordedDate_lag = lag(RecordedDate), #so we can test if record for second tuesday are plausibly next week
         dist = difftime(RecordedDate, RecordedDate_lag, units = "days"), #recoding as day between
         first_sec = seq_along(RecordedDate), #first tuesday or second tuesday?
         prob = ifelse(first_sec >= 2 & dist < 4, 1, 0)) %>% #second+ tuesday is problematic if it's NOT plausibly next week
  group_by(dyadID, partID) %>%
  arrange(dyadID, partID, RecordedDate) %>%
  mutate(rec_num = seq_along(RecordedDate),
         weekish = ifelse(rec_num > 7, 2, 1), 
         day_of_study = ifelse(weekish == 2 | (weekish==1 & first_sec>1), 
                        (case_when(day == "Monday" ~ 8,
                        day == "Tuesday" ~ 9,
                        day == "Wednesday" ~ 10,
                        day == "Thursday" ~ 11,
                        day == "Friday" ~ 12,
                        day == "Saturday" ~ 13,
                        day == "Sunday" ~ 14)), 
                      case_when(day == "Monday" ~ 1,
                        day == "Tuesday" ~ 2,
                        day == "Wednesday" ~ 3,
                        day == "Thursday" ~ 4,
                        day == "Friday" ~ 5,
                        day == "Saturday" ~ 6,
                        day == "Sunday" ~ 7)),
         week = ifelse(day_of_study > 7, 2, 1))

#selecting just what we want from daily
daily <- daily %>%
  select(partID, dyadID, RecordedDate, day, day_of_study, gender, beds:calls, 
         qmi4)

#making if they did the chore or not numeric
daily <- daily %>%
  select(-cars, -events) %>%
  mutate(beds = if_else(beds == "Yes", 1, 0),
         vacuum = if_else(vaccum == "Yes", 1, 0),
         food = if_else(food == "Yes", 1, 0),
         dishes = if_else(dishes == "Yes", 1, 0),
         garbage = if_else(garbage == "Yes", 1, 0),
         yardwork = if_else(yardwork == "Yes", 1, 0),
         pets = if_else(pets == "Yes", 1, 0),
         laundry = if_else(laundry == "Yes", 1, 0),
         errands = if_else(errands == "Yes", 1, 0),
         finances = if_else(finances == "Yes", 1, 0),
         calls = if_else(calls == "Yes", 1, 0)) %>%
  select(-vaccum) %>%
  distinct()
###############################################################################
#PREPARING FOR MERGE  
#rename the pre so that we can merge them and only include het
pre <- pre %>% 
  rename(partID = ResponseId) %>% 
  filter(sexualor == 'Heterosexual')

pre$gender <- replace(pre$gender, pre$gender == "Woman,Cis gendered", "Woman")
pre$gender <- replace(pre$gender, pre$gender == "Man,Cis gendered", "Man")

#merge the two data sets to prepare for pairwise
total <- merge(daily, pre, by = 'partID')

# Making qmi numeric
total$qmi4 <- replace(total$qmi4, total$qmi4 == 'Mostly true about me', 1)
total$qmi4 <- replace(total$qmi4, total$qmi4 == 'Somewhat true about me', 2)
total$qmi4 <- replace(total$qmi4, total$qmi4 == 'A little true about me', 3)
total$qmi4 <- replace(total$qmi4, total$qmi4 == 'Not true about me', 4)
total <- total %>%
  mutate(qmi4 = as.numeric(qmi4))

#getting rid of any NAs and making them 0
total$beds[is.na(total$beds)] = 0
total$food[is.na(total$food)] = 0
total$dishes[is.na(total$dishes)] = 0
total$garbage[is.na(total$garbage)] = 0
total$yardwork[is.na(total$yardwork)] = 0
total$pets[is.na(total$pets)] = 0
total$laundry[is.na(total$laundry)] = 0
total$errands[is.na(total$errands)] = 0
total$finances[is.na(total$finances)] = 0
total$calls[is.na(total$calls)] = 0
total$vacuum[is.na(total$vacuum)] = 0
################################################################################
#GETTING SUMS
# Summing individual daily chores
total <- total %>%
  rowwise() %>%
  mutate(ind_chores = sum(beds, food, dishes, garbage, yardwork, pets, laundry, errands, finances, calls, vacuum))

# Creating a new dataset with the sum of couple chores
couple_chores <- total %>%
  group_by(dyadID.x, day, day_of_study) %>%
  summarize(cup_chores = sum(ind_chores))

# Joining the individual and couple chore calculations 
total_chores <- merge(couple_chores, total, by = c('dyadID.x', 'day', 'day_of_study'))

# Calculating the percentage of the total chores each individual did
percent <- total_chores %>%
  group_by(dyadID.x, day, day_of_study, gender.x) %>% 
  summarize(daily_per = ifelse(cup_chores != 0, ind_chores / cup_chores, 0)) 

# Joining the individual, couple, and chore percentage calculations
final_before_pairs <- total_chores %>% 
  full_join(percent, by = c("dyadID.x", "gender.x", "day", "day_of_study"))
###############################################################################
#MAKING EVERYTHING DYADIC
# Creating a obsid
final <- final_before_pairs %>%
  mutate(obsid = day_of_study+14*(dyadID.x-1))

#finding whcih ones are greater than 2
filtered_chores <- final %>% 
  group_by(obsid) %>%
  count()

#Problems!!! we need there to only be obsid 2, anything less is fine, but anything
#above is an issue!!!
nomoreProblemshopefully <- filtered_chores %>% 
  filter(n <= 2)

#merging the set that has no problems left with the origional
fixed <- merge(nomoreProblemshopefully, final, by = 'obsid')

#putting everything in the correct order
fixed <- fixed %>% 
  select(dyadID.x, obsid, gender.x, day, day_of_study, qmi4, daily_per, bs, hs, everything())

#creating a set with just the premeasures info 
forlater <- fixed %>% 
  select(dyadID.x, obsid, day, gender.x, Q138:indinc) %>% 
  rename(dyadID = dyadID.x, 
         gender = gender.x)

# Adding gender labels and rearranging the data
pairwise <- fixed %>% 
  mutate(gender2 = gender.x, gender.x = ifelse(gender.x == 'Woman', 'A', 'P')) %>%
  select(dyadID.x, obsid, gender.x, day, day_of_study, qmi4, daily_per, bs, hs, gender2, Q138:indinc) %>% 
  rename(dyadID = dyadID.x)

# Pivoting longer
pairwise2 <- pairwise %>% 
  gather(variable, value, qmi4:Q138:indinc)

# Combining the gender and variable labels
pairwise2 <- pairwise2 %>%
  unite(var_gender, variable, gender.x) 

pairwise2 <- pairwise2 %>% 
  filter(obsid != 411584461, obsid != 411584462, obsid != 411584463, 
         obsid != 411584464, obsid != 411584465, obsid != 411584466,
         obsid != 411584467, obsid != 411584474, obsid != 411584468,
         obsid != 411584469, obsid != 411584470, obsid != 411584471,
         obsid != 411584472, obsid != 411584473)

#spread baby
pairwise2 <- pairwise2 %>% 
  pivot_wider(names_from = var_gender, values_from = value)

#filling in the categories where we know what they should be 
pairwise2$daily_per_A[is.na(pairwise2$daily_per_A)] = 0
pairwise2$daily_per_P[is.na(pairwise2$daily_per_P)] = 0
pairwise2$gender2_A[is.na(pairwise2$gender2_A)] = "Woman"
pairwise2$gender2_P[is.na(pairwise2$gender2_P)] = "Man"

# Adding gender labels and rearranging the data
pairwise3 <- fixed %>% 
  mutate(gender2 = gender.x, gender.x = ifelse(gender.x == 'Woman', 'P', 'A')) %>%
  select(dyadID.x, obsid, gender.x, day, day_of_study, qmi4, daily_per, bs, hs, gender2, Q138:indinc) %>% 
  rename(dyadID = dyadID.x)

# Pivoting longer
pairwise3 <- pairwise3 %>% 
  gather(variable, value, qmi4:indinc)

# Combining the gender and variable labels
pairwise3 <- pairwise3 %>%
  unite(var_gender, variable, gender.x)

pairwise3 <- pairwise3 %>% 
  filter(obsid != 411584461, obsid != 411584462, obsid != 411584463, 
         obsid != 411584464, obsid != 411584465, obsid != 411584466,
         obsid != 411584467, obsid != 411584474, obsid != 411584468,
         obsid != 411584469, obsid != 411584470, obsid != 411584471,
         obsid != 411584472, obsid != 411584473)

#spread baby
pairwise3 <- pairwise3 %>%
  spread(var_gender, value)

#filling in the categories where we know what they should be 
pairwise3$daily_per_A[is.na(pairwise3$daily_per_A)] = 0
pairwise3$daily_per_P[is.na(pairwise3$daily_per_P)] = 0
pairwise3$gender2_A[is.na(pairwise3$gender2_A)] = "Man"
pairwise3$gender2_P[is.na(pairwise3$gender2_P)] = "Woman"
###############################################################################
#MAKING IT PAIRWISE
#joining the datasets together
dyad_pair <- bind_rows(pairwise2, pairwise3) %>%
  arrange(obsid)
###############################################################################
#CALCULATING ICCS
#need to make man and woman 1, woman 0
workin <- dyad_pair %>% 
  mutate(gender2_A = ifelse(gender2_A == 'Woman', 0, 1),
         gender2_P = ifelse(gender2_P == 'Woman', 0, 1))

#making sure thats numeric bc idk why its not working
workin <- workin %>%
  mutate(gender2_A = as.numeric(gender2_A),
         gender2_P = as.numeric(gender2_P),
         qmi4_A = as.numeric(qmi4_A),
         qmi4_P = as.numeric(qmi4_P))

#now we running this to find the ICC for qmi
qmigoals  <- lme(qmi4_A~1,
                 data = workin, 
                 random = ~ gender2_A - 1|dyadID,
                 correlation = corCompSymm(form = ~1|dyadID/obsid),
                 weights = varIdent(form = ~1|gender2_A),
                 na.action = na.omit)
summary(qmigoals)

#now finding the ICC for percent of chores
workinpart2electricboogaloo <- workin %>%
  mutate(gender2_A = as.numeric(gender2_A),
         gender2_P = as.numeric(gender2_P),
         daily_per_A = as.numeric(daily_per_A),
         daily_per_P = as.numeric(daily_per_P))

#now running to find the ICC for average daily chores
percentlme <- lme(daily_per_A ~1,
                 data = workinpart2electricboogaloo, 
                 random = ~ gender2_A - 1|dyadID,
                 correlation = corCompSymm(form = ~1|dyadID/obsid),
                 weights = varIdent(form = ~1|gender2_A),
                 na.action = na.omit)
summary(percentlme)

#now making something for just the first rows of HS 
hsmodel <- dyad_pair %>% 
  group_by(dyadID, gender2_A) %>%
  arrange(hs_A) %>%
  filter(row_number()==1)

#making sure its numeric
hsmodel <- hsmodel %>% 
  mutate(hs_A = as.numeric(hs_A))

#running the model to find the ICCs for HS
hsfunction <- gls(hs_A ~ 1,
                  data = hsmodel,
                  correlation = corCompSymm(form=~1|dyadID), 
                  weights = varIdent(form=~1|gender2_A), 
                  na.action = na.omit)
summary(hsfunction)

#now making one for BS
bsmodel <- dyad_pair %>% 
  group_by(dyadID, gender2_A) %>%
  arrange(bs_A) %>%
  filter(row_number()==1)

#making sure its all numeric
bsmodel <- bsmodel %>% 
  mutate(bs_A = as.numeric(bs_A))

#running for the ICCS for bs
bslme <- gls(bs_A ~ 1,
             data = bsmodel,
             correlation = corCompSymm(form=~1|dyadID), 
             weights = varIdent(form=~1|gender2_A), 
             na.action = na.omit)
summary(bslme)
###############################################################################
#DEMOGRAPHICS
demographics <- dyad_pair %>%
  filter(day_of_study == 1) %>%
  select(dyadID, gender2_A, Q138_A, cohabitation_A, wfh_A, race_A, race_P, religion_A, conservatism_A, people_4_TEXT_A, people_5_TEXT_A, indinc_A)

relationship <- demographics %>%
  select(dyadID, Q138_A) %>%
  distinct() %>%
  group_by(Q138_A) %>%
  summarize(n = n())

relationship %>%
  summarize(total = sum(n))

# dyads 7403083 and 29676367 may or may not be married

relationship_cleaned <- demographics %>%
  select(dyadID, Q138_A) %>%
  filter(dyadID != 7403083, dyadID != 29676367) %>%
  distinct() %>%
  group_by(Q138_A) %>%
  summarize(n = n())

relationship_cleaned %>%
  summarize(total = sum(n))

cohab <- demographics %>%
  select(dyadID, cohabitation_A) %>%
  distinct() %>%
  group_by(cohabitation_A) %>%
  summarize(n = n())

cohab %>%
    summarize(total = sum(n))

children <- demographics %>%
  select(dyadID, people_4_TEXT_A, people_5_TEXT_A) %>%
  mutate(kids = as.numeric(people_4_TEXT_A),
         teens = as.numeric(people_5_TEXT_A)) %>%
  select(dyadID, kids, teens) %>%
  replace(is.na(.), 0) %>%
  mutate(total_children = kids + teens) %>%
  select(dyadID, kids, teens, total_children) %>%
   distinct() %>%
  group_by(total_children) %>%
  summarize(n = n())

children %>%
  summarize(total = sum(n))

testing_kids <- demographics %>%
  select(dyadID, people_4_TEXT_A, people_5_TEXT_A) %>%
  mutate(kids = as.numeric(people_4_TEXT_A),
         teens = as.numeric(people_5_TEXT_A)) %>%
  select(dyadID, kids) %>%
  group_by(dyadID, kids) %>%
  summarize(n = n()) %>%
  filter(n <2)

# dyads 29508533 and 29237405 may either have 1 or 2 kids
# dyad 18756718 may have either 0 or 2 kids

testing_teens <- demographics %>%
  select(dyadID, people_4_TEXT_A, people_5_TEXT_A) %>%
  mutate(kids = as.numeric(people_4_TEXT_A),
         teens = as.numeric(people_5_TEXT_A),
         total_children = kids + teens) %>%
  select(dyadID, teens) %>%
  group_by(dyadID, teens) %>%
  summarize(n = n()) %>%
  filter(n <2)

# dyad 18324617 has 1 or 2 teens
# dyad 18756718 has 2 or 4 teens (2 from kids?)
# dyad 29508533 has 0 or 1 teens (1 from kids)
# dyad 29725014 has 2 or 1 teens

cleaner_children <- demographics %>%
  select(dyadID, people_4_TEXT_A, people_5_TEXT_A) %>%
  mutate(kids = as.numeric(people_4_TEXT_A),
         teens = as.numeric(people_5_TEXT_A)) %>%
  select(dyadID, kids, teens) %>%
   filter(dyadID != 29508533, dyadID != 29237405, dyadID != 18756718, 
          dyadID != 18324617, dyadID != 29725014) %>%
  replace(is.na(.), 0) %>%
  mutate(total_children = kids + teens) %>%
  select(dyadID, total_children) %>%
  filter(total_children != 0) %>%
  distinct() %>%
  add_row(dyadID = 29508533, total_children = 2) %>%
  group_by(total_children) %>%
  summarize(n = n())

more_than_one <- cleaner_children %>%
  summarize(total = sum(n)) 

cleaner_children <- cleaner_children %>%
  add_row(total_children = 0, n = 264/2 - more_than_one$total)
  

cleaner_children %>%
  summarize(total = sum(n)) 

ind_race <- demographics %>%
  group_by(race_A) %>%
  summarize(n = n())

ind_race %>%
  summarize(total = sum(n))

mixed_race_couples <- demographics %>%
  filter(race_A != race_P) %>%
  select(dyadID) %>%
  distinct()

mixed_race_couples %>%
  summarize(n = n())

religion <- demographics %>%
  group_by(religion_A) %>%
  summarize(n = n())

religion %>%
    summarize(total = sum(n))

politics <- demographics %>%
  group_by(conservatism_A) %>%
  summarize(n = n())

politics %>%
  summarize(total = sum(n))
```

# Methods

## Measures

### Independent Variables

Hostile sexism (HS) and benevolent sexism (BS) were measured using a modified version of the Ambivalent Sexism Inventory (ASI) created by @ASI. The original scale includes 22 questions with 11 for both subcategories of sexism; however, we removed question 18, “There are actually very few women who get a kick out of teasing men by seeming sexually available and then refusing male advances”. Participants did not appear to understand the wording of the question, and responses were inconsistent with their other answers. Therefore, our final data includes 10 questions assessing HS and 12 assessing BS. A higher score for either scale indicates higher sexist beliefs. Alphas for HS and BS were .87 and .80 respectively and the intraclass correlations were .59 and .32. 

To calculate the division of household labor we asked each participant to complete 14 daily diaries, in which they were given a list of routine chores and were asked to indicate, “Today, did you spend any time on the following household chores?" Since we are looking to isolate routine chores, we chose to omit intermittent chores from our calculation of housework. We removed the responses to the categories “Took care of our cars today (sent to repairs, washing, vacuuming)” and “Prepared for events and activities today (for example, birthdays or anniversaries)”. We also chose not to include text responses of additional chores because most of them fell into other chore categories or were better described as intermittent. There were 11 remaining chores (e.g., laundry, cooking, yardwork, etc.) and the intraclass correlation was .38.

### Response Variable

In order to assess feelings about working together, participants were asked about the degree to which they identified with the statement: “Today, my partner and I are really a team” in their daily diaries. Their answers were scored on a four point scale, with possible responses ranging from *mostly true about me* to *not true about me*. A higher score was associated with lower feelings about the quality of teamwork for the day. The intraclass correlation for this variable was -0.91.


## Participants

While the original data set includes 364 participants of all identities, it predominantly consists of heterosexual individuals (*n* = 353). In order to examine division of labor along gender lines, it is necessary to restrict the data set to male-female couples. Due to the small number of male-female couples that included an individual who was not heterosexual, we decided to restrict our sample further to only include heterosexual couples. This was done in order to prevent any confounds that sexual orientation may have caused. Additionally, since all of the couples were living together, we included both couples who were married and those who were in long-term relationships. Regardless of marital status, couples who have lived together for some time need to find ways to divide their housework, and are therefore relevant to our study.

After cleaning the data and filtering out any missing or problematic data points, we were left with 272 individuals (136 dyads). Of the participants, there were 127 married couples, 7 couples that were in committed, long-term relationships and 2 couples where one individual answered that they were married and the other answered that they were in a long-term relationship. All 136 of the couples answered that they were living together. Notably, 50 participants didn’t answer any of the demographic information. In these cases, the partner’s information was used in calculating these numbers. When looking at other household members, 45 of the couples had children under the age of 18 living in their homes. 36 had one child, 31 had two, 13 had three, and 5 had four. Additionally, one couple reported having ten children, and another reported having 26. These two cases may have been participant error when they were inputting the amount of children in their households as text answers. Five couples had one individual report a different number of children than the other. Those who did not answer the questions were coded as having no children. 

A majority of the participants were White (_n_ = 165). 24 participants identified as Asian, 17 identified as Black or African American, 9 identified as Hispanic or Latinx, 2 as Middle Eastern, 3 as White and Hispanic/Latinx, and 52 either did not answer or chose the “prefer not to answer” option. 9 of the couples were mixed-race couples. A majority of the individuals identified themselves as Christian (_n_ = 150). A wide assortment of other religions were also represented, but none had more than 15 people affiliated with them. In terms of political affiliations, there was a pretty equal distribution along the spectrum. Most of the individuals were at or around the center of the spectrum, with a slight skew towards conservatism.

```{r table, echo = FALSE}
#finding the means and SD for HS based on gender
hsmodel %>% 
  group_by(gender2_A) %>%
  na.omit(hs_A) %>% 
  summarize(n= n(),m = mean(hs_A), sd = sd(hs_A))

#finding the means and SD for BS based on gender
bsmodel %>% 
  group_by(gender2_A) %>% 
  na.omit(bs_A) %>% 
  na.omit(hs_A) %>% 
  summarize(n = n(), m = mean(bs_A), sd = sd(bs_A))


bsmodel <- bsmodel %>% 
  na.omit(bs_A, hs_A) %>% 
  mutate(hs_A = as.numeric(hs_A),
         bs_A = as.numeric(bs_A)) 


bsmodel <- bsmodel %>%
  mutate(bs_A = as.numeric(bs_A),
         hs_A = as.numeric(hs_A))

corr.test(bsmodel$bs_A, bsmodel$hs_A)$r
corr.test(bsmodel$bs_A, bsmodel$hs_A)$p

# Husband
asi_husband <- pairwise2 %>%
  filter(day_of_study == 1) %>%
    mutate(bs_P = as.numeric(bs_P),
           hs_P = as.numeric(hs_P)) %>%
  select(bs_P, hs_P)

husband_corr <- corr.test(asi_husband$bs_P, asi_husband$hs_P)

husband_corr$r
husband_corr$p

# Wife
asi_wife <- pairwise2 %>%
  filter(day_of_study == 1) %>%
    mutate(bs_A = as.numeric(bs_A),
           hs_A = as.numeric(hs_A)) %>%
  select(bs_A, hs_A)

wife_corr <- corr.test(asi_wife$bs_A, asi_wife$hs_A)

wife_corr$r
wife_corr$p

#alpha for benevolent
alpha(select(pre, asi_1, asi_3.r, asi_6.r, asi_8, asi_9, asi_12, asi_13.r, asi_17, asi_19, asi_20, asi_22))
#raw alpha is 0.8001697

# Reliability for the hostile
alpha(select(pre, asi_2, asi_4, asi_5, asi_7.r, asi_10, asi_11, asi_14, asi_15, asi_16, asi_21.r))
#raw alpha is 0.8743657 without question 18

#creating the table using the kableExtra package
tab <- data.frame(
  'Sexism Scales' = c('Hostile Sexism', 'Benevolent Sexism'),
  'Mean' = c(3.56, 3.95),
  'SD' = c(0.81, 0.696),
  'Mean ' = c(3.23, 3.71),
  'SD ' = c(1.01, 0.72),
  'Alpha' = c(.8, .87),
  'Hostile Sexism' = c(1, '0.024'),
  'Benevolent Sexism' = c('0.36', 1))

#creating the table
tab %>%
  kbl(caption = "Table 1. Descriptive Statistics, Correlations Across Sexism Scores") %>% 
  kable_minimal() %>% 
  add_header_above(c(" " = 1, "Men" = 2, "Women" = 2," "= 1, "Correnlations" = 2)) %>% 
  footnote(general = "Possible hostile and benevolent scores range from 1 to 7. Correlation for men are above the diagonal. Correlations for women are below the diagonal.")
```


## Data analysis
We used `r cite_r("r-references.bib")` for all our analyses.



\newpage

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup
